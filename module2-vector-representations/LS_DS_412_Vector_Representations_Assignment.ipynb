{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Vector Representations\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "hyj-f9FDcVFp",
    "outputId": "5dd045fe-6e4c-458c-e2fc-253c3da9c805"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7bcmqfGXrFG"
   },
   "source": [
    "## 1) *Clean:* Job Listings from indeed.com that contain the title \"Data Scientist\" \n",
    "\n",
    "You have `job_listings.csv` in the data folder for this module. The text data in the description column is still messy - full of html tags. Use the [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) library to clean up this column. You will need to read through the documentation to accomplish this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcYlc1URXhlC"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "df = pd.read_csv('job_listings.csv')\n",
    "##### Your Code Here #####\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0  b\"<div><div>Job Requirements:</div><ul><li><p>...   \n",
       "1           1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...   \n",
       "2           2  b'<div><p>As a Data Scientist you will be work...   \n",
       "3           3  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
       "4           4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n",
       "\n",
       "                          title  \n",
       "0               Data scientistÂ   \n",
       "1              Data Scientist I  \n",
       "2  Data Scientist - Entry Level  \n",
       "3                Data Scientist  \n",
       "4                Data Scientist  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>description</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n      <td>Data scientist</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n      <td>Data Scientist I</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n      <td>Data Scientist - Entry Level</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n      <td>Data Scientist</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n      <td>Data Scientist</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 185
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scrape = [df['description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0      b\"<div><div>Job Requirements:</div><ul><li><p>...\n",
       " 1      b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...\n",
       " 2      b'<div><p>As a Data Scientist you will be work...\n",
       " 3      b'<div class=\"jobsearch-JobMetadataHeader icl-...\n",
       " 4      b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...\n",
       "                              ...                        \n",
       " 421    b\"<b>About Us:</b><br/>\\nWant to be part of a ...\n",
       " 422    b'<div class=\"jobsearch-JobMetadataHeader icl-...\n",
       " 423    b'<div class=\"jobsearch-JobMetadataHeader icl-...\n",
       " 424    b\"<p></p><div><p>SENIOR DATA SCIENTIST</p><p>\\...\n",
       " 425    b'<div></div><div><div><div><div><p>Cerner Int...\n",
       " Name: description, Length: 426, dtype: object]"
      ]
     },
     "metadata": {},
     "execution_count": 187
    }
   ],
   "source": [
    "to_scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['soup_text'] = [BeautifulSoup(text).get_text() for text in df['description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'b\"Job Requirements:\\\\nConceptual understanding in Machine Learning models like Nai\\\\xc2\\\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them\\\\nIntermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role)\\\\nExposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R\\\\nAbility to communicate Model findings to both Technical and Non-Technical stake holders\\\\nHands on experience in SQL/Hive or similar programming language\\\\nMust show past work via GitHub, Kaggle or any other published article\\\\nMaster\\'s degree in Statistics/Mathematics/Computer Science or any other quant specific field.\\\\nApply Now\"'"
      ]
     },
     "metadata": {},
     "execution_count": 150
    }
   ],
   "source": [
    "df['soup_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_description(description):\n",
    "    pos = re.sub(r'.\\\\n', ' ', description)\n",
    "    return pos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['soup_text'] = df['soup_text'].replace(r'.\\\\n', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['soup_text'] = df['soup_text'].replace(r'.\\\\xe2\\\\x80\\\\x99', \"'\", regex=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['soup_text'] = df['soup_text'].replace(r'.\\\\xe2\\\\x80\\\\xa', \"\", regex=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['soup_text'] = df['soup_text'].apply(get_lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4xFZNtX1m2"
   },
   "source": [
    "## 2) Use Spacy to tokenize the listings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhUHuMr-X-II"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = nlp.Defaults.stop_words.union(['b\"job', 'requirements', 'data', 'scientists', \"job\", \"b'job\", \"you\\'ll\", \"x80\", \"x93\", \"xe2\", \t\"you\\'re\", \"\\ntoday\" ])\n",
    "\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "\n",
    "for doc in tokenizer.pipe(df['soup_text']):\n",
    "\n",
    "    doc_tokens =[]\n",
    "\n",
    "    for token in doc:\n",
    "        if token.text.lower() not in STOP_WORDS:\n",
    "            doc_tokens.append(token.text.lower())\n",
    "    tokens.append(doc_tokens)\n",
    "df['tokens'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0      [conceptual, understanding, machine, learning,...\n",
       "1      [descriptio, \\nas, scientist, 1,, help, build,...\n",
       "2      [b'as, scientist, working, consulting, busines...\n",
       "3      [b'$4,969, -, $6,756, monthcontractunder, gene...\n",
       "4      [b'location:, usa, \\xe2\\x80\\x93, multiple, loc...\n",
       "                             ...                        \n",
       "421    [b\"about, want, fantastic, fun, startup, tha's...\n",
       "422    [b'internshipat, uber,, ignite, opportunity, s...\n",
       "423    [b'$200,000, -, $350,000, yeara, million, peop...\n",
       "424    [b\"senior, scientis, descriptio, \\nabout, u, \\...\n",
       "425    [b'cerner, intelligence, new,, innovative, org...\n",
       "Name: tokens, Length: 426, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 279
    }
   ],
   "source": [
    "df['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemmas(text):\n",
    "\n",
    "    lemmas = []\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Something goes here :P\n",
    "    for token in doc: \n",
    "        if ((token.is_stop == False) and (token.is_punct == False)):\n",
    "            lemmas.append(token.lemma_)\n",
    "    \n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listToString(s):\n",
    "\n",
    "    str1=\" \"\n",
    "    return (str1.join(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['tokens'].apply(listToString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lgCZNL_YycP"
   },
   "source": [
    "## 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2PZ8Pj_YxcF"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words='english',\n",
    "                       max_df=.90,\n",
    "                       min_df=.10)\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = vect.fit_transform(df['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   ability  able  access  achieve  action  actionable  ad  additional  \\\n",
       "0        2     0       0        0       0           0   0           0   \n",
       "1        1     0       0        0       0           0   0           1   \n",
       "2        1     0       0        0       0           1   0           0   \n",
       "3        0     0       0        0       1           0   0           0   \n",
       "4        0     0       0        0       0           0   0           0   \n",
       "\n",
       "   address  advanced  ...  worl  world  writing  written  x80  x93  xe2  year  \\\n",
       "0        0         0  ...     0      0        0        0    0    0    0     0   \n",
       "1        0         0  ...     0      2        2        1    0    0    0     1   \n",
       "2        0         1  ...     0      0        0        0    0    0    0     0   \n",
       "3        0         0  ...     0      0        0        0    0    0    0     1   \n",
       "4        0         0  ...     0      0        0        0    1    1    1     0   \n",
       "\n",
       "   years  yo  \n",
       "0      0   0  \n",
       "1      0   0  \n",
       "2      0   0  \n",
       "3      0   0  \n",
       "4      1   0  \n",
       "\n",
       "[5 rows x 520 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ability</th>\n      <th>able</th>\n      <th>access</th>\n      <th>achieve</th>\n      <th>action</th>\n      <th>actionable</th>\n      <th>ad</th>\n      <th>additional</th>\n      <th>address</th>\n      <th>advanced</th>\n      <th>...</th>\n      <th>worl</th>\n      <th>world</th>\n      <th>writing</th>\n      <th>written</th>\n      <th>x80</th>\n      <th>x93</th>\n      <th>xe2</th>\n      <th>year</th>\n      <th>years</th>\n      <th>yo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã 520 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 269
    }
   ],
   "source": [
    "dtm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zo1iH_UeY7_n"
   },
   "source": [
    "## 4) Visualize the most common word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5LB00uyZKV5"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwFsTqrVZMYi"
   },
   "source": [
    "## 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(document):\n",
    "    \"\"\"\n",
    "    Takes a doc and returns a list of tokens in the form of lemmas.\n",
    "    Stop words and punctuation are filtered out. \n",
    "    \"\"\"\n",
    "    \n",
    "    doc = nlp(document)\n",
    "    \n",
    "    return [token.lemma_.strip() for token in doc if (token.is_stop != True) and (token.is_punct != True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gx2gZCbl5Np"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "tfidf = TfidfVectorizer(stop_words='english', \n",
    "                        ngram_range=(1,2),\n",
    "                        max_df=.97,\n",
    "                        min_df=3,\n",
    "                        tokenizer=tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_tfidf = tfidf.fit_transform(df['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_tfidf = pd.DataFrame(dtm_tfidf.todense(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                \\ntoday   ability   clearance   design   excellent  \\\n",
       "0    0.076140       0.0  0.143124         0.0      0.0         0.0   \n",
       "1    0.034248       0.0  0.000000         0.0      0.0         0.0   \n",
       "2    0.000000       0.0  0.000000         0.0      0.0         0.0   \n",
       "3    0.000000       0.0  0.000000         0.0      0.0         0.0   \n",
       "4    0.000000       0.0  0.000000         0.0      0.0         0.0   \n",
       "..        ...       ...       ...         ...      ...         ...   \n",
       "421  0.000000       0.0  0.000000         0.0      0.0         0.0   \n",
       "422  0.000000       0.0  0.000000         0.0      0.0         0.0   \n",
       "423  0.000000       0.0  0.000000         0.0      0.0         0.0   \n",
       "424  0.000000       0.0  0.000000         0.0      0.0         0.0   \n",
       "425  0.000000       0.0  0.000000         0.0      0.0         0.0   \n",
       "\n",
       "      experience   hand   proficiency   provide  ...      york  york city  \\\n",
       "0            0.0    0.0           0.0       0.0  ...  0.000000        0.0   \n",
       "1            0.0    0.0           0.0       0.0  ...  0.000000        0.0   \n",
       "2            0.0    0.0           0.0       0.0  ...  0.000000        0.0   \n",
       "3            0.0    0.0           0.0       0.0  ...  0.000000        0.0   \n",
       "4            0.0    0.0           0.0       0.0  ...  0.000000        0.0   \n",
       "..           ...    ...           ...       ...  ...       ...        ...   \n",
       "421          0.0    0.0           0.0       0.0  ...  0.039943        0.0   \n",
       "422          0.0    0.0           0.0       0.0  ...  0.000000        0.0   \n",
       "423          0.0    0.0           0.0       0.0  ...  0.000000        0.0   \n",
       "424          0.0    0.0           0.0       0.0  ...  0.000000        0.0   \n",
       "425          0.0    0.0           0.0       0.0  ...  0.000000        0.0   \n",
       "\n",
       "     york office   you\\'ll  you\\'ll d  you\\'ll work  you\\'re  yrs    |   ||  \n",
       "0            0.0  0.000000   0.000000           0.0      0.0  0.0  0.0  0.0  \n",
       "1            0.0  0.000000   0.000000           0.0      0.0  0.0  0.0  0.0  \n",
       "2            0.0  0.000000   0.000000           0.0      0.0  0.0  0.0  0.0  \n",
       "3            0.0  0.000000   0.000000           0.0      0.0  0.0  0.0  0.0  \n",
       "4            0.0  0.000000   0.000000           0.0      0.0  0.0  0.0  0.0  \n",
       "..           ...       ...        ...           ...      ...  ...  ...  ...  \n",
       "421          0.0  0.000000   0.000000           0.0      0.0  0.0  0.0  0.0  \n",
       "422          0.0  0.110078   0.073072           0.0      0.0  0.0  0.0  0.0  \n",
       "423          0.0  0.000000   0.000000           0.0      0.0  0.0  0.0  0.0  \n",
       "424          0.0  0.000000   0.000000           0.0      0.0  0.0  0.0  0.0  \n",
       "425          0.0  0.000000   0.000000           0.0      0.0  0.0  0.0  0.0  \n",
       "\n",
       "[426 rows x 11903 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>\\ntoday</th>\n      <th>ability</th>\n      <th>clearance</th>\n      <th>design</th>\n      <th>excellent</th>\n      <th>experience</th>\n      <th>hand</th>\n      <th>proficiency</th>\n      <th>provide</th>\n      <th>...</th>\n      <th>york</th>\n      <th>york city</th>\n      <th>york office</th>\n      <th>you\\'ll</th>\n      <th>you\\'ll d</th>\n      <th>you\\'ll work</th>\n      <th>you\\'re</th>\n      <th>yrs</th>\n      <th>|</th>\n      <th>||</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.076140</td>\n      <td>0.0</td>\n      <td>0.143124</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.034248</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>421</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.039943</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>422</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.110078</td>\n      <td>0.073072</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>423</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>424</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>425</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>426 rows Ã 11903 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 276
    }
   ],
   "source": [
    "dtm_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Create a NearestNeighbor Model. Write the description of your ideal datascience job and query your job listings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "                 metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "metadata": {},
     "execution_count": 282
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "nn = NearestNeighbors(algorithm=\"kd_tree\")\n",
    "nn.fit(dtm_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([0.07613972, 0.        , 0.14312408, ..., 0.        , 0.        ,\n",
       "        0.        ])]"
      ]
     },
     "metadata": {},
     "execution_count": 284
    }
   ],
   "source": [
    "doc_index = 0\n",
    "doc_vect = [dtm_tfidf.iloc[doc_index].values]\n",
    "doc_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_desc = [\"\"\"ideal candidate can code well in python and use relevant modules to data science. we have a clear drive towards the future of green energy\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = tfidf.transform(ideal_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[1.33156575, 1.33598471, 1.33845594, 1.34250948, 1.35195631]]),\n",
       " array([[ 62, 308, 368, 297, 325]], dtype=int64))"
      ]
     },
     "metadata": {},
     "execution_count": 289
    }
   ],
   "source": [
    "nn.kneighbors(new.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"b'Business Unit Introduction \\\\nThis position is in the Enterprise Digital and Analytics \\\\xe2\\\\x80\\\\x93 Global Customer Data Science team and is responsible for driving positive value for the consumer base, our internal partners and shareholders through best-in-class data and decision science \\\\nThe Team Our team is the decision science team with emphasis on optimization, simulation, reinforcement learning, and Natural Language Processing (NLP). We are responsible for the innovation of the AMEX Chatbot module and the optimization layer of Orchestra, a cross-channel content delivery system \\\\nResponsibilities and Value Proposition applying rigorious data science and optimization techniques on digital advertising helping our customer care professionals to reolve card members\\\\' issues faster and more accurately by utilizing NLP techniques collaborating with internal production teams to build and launch machine learning products monitoring and delivering insightful analytics on model performances \\\\nThis role is ideal for someone who wants to develop a research & development career in the digital payments space while learning and applying related machine learning techniques from data collection to advertisement distribution channels, including chatbot \\\\nQualification Minimum Qualifications Masters/PhD in Computer Science, Statistics, (Applied) Mathematics, and/or Operations Research Strong fundamental knowledge of linear algebra and hypothesis testing Extensive knowledge and practical experience on machine learning techniques including regression & classification methods, boosting methods, and neural networks Basic theoretical and algorithmic understanding of stochastic processes and statistical modeling, e.g. Dynamic Programming, Markov Decision Process, and Language Modeling Proficient in Python (along with TensorFlow and/or PyTorch), Hive, and Spark Independent contributor with strong interpersonal, communication, and writing skills Ideal Candidate PhD with 1-2 years of practical experience in building machine learning production modules Hands-on experience with ad-ranking and dialog managemen Prior experience on building interactive prototypes using Django and visualizing data using D3.js Depending on factors such as business unit requirements, the nature of the position, cost and applicable laws, American Express may provide visa sponsorship for certain positions \\\\ ReqID: 1900416 Schedule (Full-Time/Part-Time): Full-tim Date Posted: Mar 6, 2019, 5:17:25 PM'\""
      ]
     },
     "metadata": {},
     "execution_count": 290
    }
   ],
   "source": [
    "df['soup_text'][62]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiDfTWceoRkH"
   },
   "source": [
    "## Stretch Goals\n",
    "\n",
    " - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n",
    " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
    " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
    " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
    "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data.\n",
    " - Create a labeled dataset - which jobs will you apply for? Train a model to select the jobs you are most likely to apply for. :) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_422_BOW_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "3d1d960ca4697622d3d0a46ce543117a174eb0141bdd63e915cadcc53c2b6a87"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}